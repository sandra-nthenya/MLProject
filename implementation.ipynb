{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkvshZ_ek1UM",
        "outputId": "c9989c0e-4df9-47e9-8aef-6a9303de94e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow numpy librosa matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHSXhjTkk1UO"
      },
      "outputs": [],
      "source": [
        "#pip install tensorflow keras numpy pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF16ztJlk1UP",
        "outputId": "84d8730e-d5ce-44c1-97f6-07dc30a0f809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataFrame:\n",
            "                     label                                               text\n",
            "2401 Borderlands  Positive  im getting on borderlands and i will murder yo...\n",
            "     Borderlands  Positive  I am coming to the borders and I will kill you...\n",
            "     Borderlands  Positive  im getting on borderlands and i will kill you ...\n",
            "     Borderlands  Positive  im coming on borderlands and i will murder you...\n",
            "     Borderlands  Positive  im getting on borderlands 2 and i will murder ...\n",
            "\n",
            "Validation DataFrame:\n",
            "                     label                                               text\n",
            "3364 Facebook   Irrelevant  I mentioned on Facebook that I was struggling ...\n",
            "352  Amazon        Neutral  BBC News - Amazon boss Jeff Bezos rejects clai...\n",
            "8312 Microsoft    Negative  @Microsoft Why do I pay for WORD when it funct...\n",
            "4371 CS-GO        Negative  CSGO matchmaking is so full of closet hacking,...\n",
            "4433 Google        Neutral  Now the President is slapping Americans in the...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "df_train = pd.read_csv('/content/twitter_training.csv', names=['label', 'text'])\n",
        "df_val = pd.read_csv('/content/twitter_validation.csv', names=['label', 'text'])\n",
        "\n",
        "# Display the first few rows of each dataframe\n",
        "print(\"Training DataFrame:\")\n",
        "print(df_train.head())\n",
        "\n",
        "print(\"\\nValidation DataFrame:\")\n",
        "print(df_val.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynwM2chbk1UP",
        "outputId": "46d97784-5de9-447a-82c5-52ff36f35364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hKAVzGd9k1UP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Text cleaning and preprocessing\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):  # Check if text is a string\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "        text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "    else:\n",
        "        text = \"\"  # Replace non-string values with an empty string\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to both training and validation dataframes\n",
        "df_train['cleaned_text'] = df_train['text'].apply(clean_text)\n",
        "df_val['cleaned_text'] = df_val['text'].apply(clean_text)\n",
        "\n",
        "# Keep track of indices during the split\n",
        "df_train_with_index = df_train.copy()\n",
        "df_train_with_index.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Split data while retaining indices\n",
        "X_train_text, X_test_text, y_train, y_test, idx_train, idx_test = train_test_split(\n",
        "    df_train_with_index['cleaned_text'], df_train_with_index['label'], df_train_with_index.index, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenization and padding (fitting on training data and transforming both)\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(X_train_text)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(X_test_text)\n",
        "X_test = pad_sequences(X_test, maxlen=100)\n",
        "\n",
        "# Convert labels to categorical for both datasets\n",
        "y_train = pd.get_dummies(y_train).values\n",
        "y_test = pd.get_dummies(y_test).values\n",
        "\n",
        "# The resulting X_train, X_test, y_train, and y_test are ready for model training and evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lStzhC2Zk1UP",
        "outputId": "0b0ec950-e201-4bd0-e22c-4ce6cc4cda3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in training set: 4\n",
            "Number of classes in validation set: 4\n"
          ]
        }
      ],
      "source": [
        "num_classes_train = y_train.shape[1]\n",
        "num_classes_val = y_test.shape[1]\n",
        "\n",
        "print(f\"Number of classes in training set: {num_classes_train}\")\n",
        "print(f\"Number of classes in validation set: {num_classes_val}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "CH1z4GxO2dgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "RWqOTQfok1UQ",
        "outputId": "b4b2e86b-7ba5-4dd8-cf0f-0a550e2ee398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Building the CNN + LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim=20000, output_dim=128, input_length=100))\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# LSTM layer\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer: Assuming four classes (e.g., positive, negative, neutral, and one more)\n",
        "model.add(Dense(4, activation='softmax'))  # Updated to 4 units\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q41JIT3vk1UQ",
        "outputId": "392f122a-dcb7-4b0e-c258-aa9045de0fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "747/747 - 107s - 144ms/step - accuracy: 0.5533 - loss: 1.0519 - val_accuracy: 0.6998 - val_loss: 0.7825\n",
            "Epoch 2/10\n",
            "747/747 - 142s - 190ms/step - accuracy: 0.8007 - loss: 0.5583 - val_accuracy: 0.7926 - val_loss: 0.5596\n",
            "Epoch 3/10\n",
            "747/747 - 102s - 137ms/step - accuracy: 0.8758 - loss: 0.3475 - val_accuracy: 0.8183 - val_loss: 0.5306\n",
            "Epoch 4/10\n",
            "747/747 - 146s - 196ms/step - accuracy: 0.9095 - loss: 0.2449 - val_accuracy: 0.8236 - val_loss: 0.5417\n",
            "Epoch 5/10\n",
            "747/747 - 140s - 188ms/step - accuracy: 0.9305 - loss: 0.1846 - val_accuracy: 0.8237 - val_loss: 0.5943\n",
            "Epoch 6/10\n",
            "747/747 - 108s - 144ms/step - accuracy: 0.9410 - loss: 0.1553 - val_accuracy: 0.8274 - val_loss: 0.6293\n",
            "Epoch 7/10\n",
            "747/747 - 149s - 200ms/step - accuracy: 0.9495 - loss: 0.1275 - val_accuracy: 0.8385 - val_loss: 0.6336\n",
            "Epoch 8/10\n",
            "747/747 - 130s - 173ms/step - accuracy: 0.9537 - loss: 0.1160 - val_accuracy: 0.8348 - val_loss: 0.7089\n",
            "Epoch 9/10\n",
            "747/747 - 145s - 194ms/step - accuracy: 0.9568 - loss: 0.1077 - val_accuracy: 0.8435 - val_loss: 0.7166\n",
            "Epoch 10/10\n",
            "747/747 - 138s - 185ms/step - accuracy: 0.9590 - loss: 0.0972 - val_accuracy: 0.8443 - val_loss: 0.7504\n",
            "467/467 - 9s - 19ms/step - accuracy: 0.8429 - loss: 0.7511\n",
            "Test Accuracy: 0.8428733944892883\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Evaluate on the test set\n",
        "score, acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'Test Accuracy: {acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62VBwR0Nk1UQ",
        "outputId": "3a629a18-dc4b-45a9-f891-ea73ed23bac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.84      0.80      0.82      2592\n",
            "     Neutral       0.87      0.87      0.87      4519\n",
            "    Positive       0.79      0.84      0.82      3596\n",
            "  Irrelevant       0.86      0.85      0.86      4230\n",
            "\n",
            "    accuracy                           0.84     14937\n",
            "   macro avg       0.84      0.84      0.84     14937\n",
            "weighted avg       0.84      0.84      0.84     14937\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert the one-hot encoded predictions and true labels to class indices\n",
        "predictions = model.predict(X_test)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_true, y_pred, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lpehknjbk1UQ"
      },
      "outputs": [],
      "source": [
        "def predict_classes(sample_text):\n",
        "    cleaned_sample_text = clean_text(sample_text)\n",
        "\n",
        "    # Tokenize and pad the text\n",
        "    sample_sequence = tokenizer.texts_to_sequences([cleaned_sample_text])\n",
        "    sample_padded = pad_sequences(sample_sequence, maxlen=100)\n",
        "    # Predict the class using the model\n",
        "    sample_prediction = model.predict(sample_padded)\n",
        "\n",
        "    predicted_class = np.argmax(sample_prediction, axis=1)[0]\n",
        "    class_names = ['Negative', 'Neutral', 'Positive', 'Irrelevant']\n",
        "    print(f\"Sample Text: {sample_text}\")\n",
        "    print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
        "\n",
        "\n",
        "\n",
        "def predict_sarcasm(text):\n",
        "    if not isinstance(text, str):\n",
        "        print(\"Text entered is not a string\")\n",
        "        return\n",
        "\n",
        "    # Normalize text\n",
        "    text = text.lower().strip()\n",
        "\n",
        "    # sarcasm-related patterns\n",
        "    sarcasm_patterns = [\n",
        "        r'\\byeah,? right\\b',\n",
        "        r'\\btotally\\b',\n",
        "        r'\\bsure\\b',\n",
        "        r'\\bof course\\b',\n",
        "        r'\\bas if\\b',\n",
        "        r'\\bgreat,? just what i needed\\b',\n",
        "        r'\\blove that for me\\b',\n",
        "        r'\\bwhat a surprise\\b',\n",
        "        r'\\bthanks a lot\\b',\n",
        "    ]\n",
        "\n",
        "    # Punctuation or formatting cues\n",
        "    punctuation_patterns = [\n",
        "        r'!{2,}',  # Multiple exclamation marks\n",
        "        r'\\.{3,}',  # Ellipses\n",
        "        r'\\b(not|never|no way) (really|totally|at all)\\b',  # Contrasting sentiments\n",
        "    ]\n",
        "\n",
        "    # Check sarcasm patterns\n",
        "    for pattern in sarcasm_patterns + punctuation_patterns:\n",
        "        if re.search(pattern, text):\n",
        "            print(\"Sarcastic\")\n",
        "\n",
        "    print(\"Not Sarcastic\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2svbgYzk1UR",
        "outputId": "1ecb36fe-2ce8-44d0-fe6c-99c56873be5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Sample Text: I absolutely love this product, it is fantastic!\n",
            "Predicted Class: Irrelevant\n",
            "Not Sarcastic\n"
          ]
        }
      ],
      "source": [
        "sample_text = \"I absolutely love this product, it is fantastic!\"\n",
        "predict_classes(sample_text)\n",
        "predict_sarcasm(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V59mIW36tkvY",
        "outputId": "1a30433f-984d-4510-9d17-a0c4d58c72bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "d4U6Plpqvb5r"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaMgE-4tuOMp",
        "outputId": "3056d77d-0aef-4078-9183-3a4c7450fb83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "with open('/content/tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "model = load_model(\"/content/model.h5\")\n",
        "\n",
        "# Cleaning Function\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Functions\n",
        "def predict_classes(sample_text):\n",
        "    cleaned_sample_text = clean_text(sample_text)\n",
        "\n",
        "    # Tokenize and pad the text\n",
        "    sample_sequence = tokenizer.texts_to_sequences([cleaned_sample_text])\n",
        "    sample_padded = pad_sequences(sample_sequence, maxlen=100)\n",
        "\n",
        "    # Predict the class using the model\n",
        "    sample_prediction = model.predict(sample_padded)\n",
        "    predicted_class = np.argmax(sample_prediction, axis=1)[0]\n",
        "\n",
        "    class_names = ['Negative', 'Neutral', 'Positive', 'Irrelevant']\n",
        "    return class_names[predicted_class]\n",
        "\n",
        "def predict_sarcasm(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"Text entered is not a string\"\n",
        "\n",
        "    # Normalize text\n",
        "    text = text.lower().strip()\n",
        "\n",
        "    # sarcasm-related patterns\n",
        "    sarcasm_patterns = [\n",
        "        r'\\byeah,? right\\b',\n",
        "        r'\\btotally\\b',\n",
        "        r'\\bsure\\b',\n",
        "        r'\\bof course\\b',\n",
        "        r'\\bas if\\b',\n",
        "        r'\\bgreat,? just what i needed\\b',\n",
        "        r'\\blove that for me\\b',\n",
        "        r'\\bwhat a surprise\\b',\n",
        "        r'\\bthanks a lot\\b',\n",
        "    ]\n",
        "\n",
        "    # Punctuation or formatting cues\n",
        "    punctuation_patterns = [\n",
        "        r'!{2,}',  # Multiple exclamation marks\n",
        "        r'\\.{3,}',  # Ellipses\n",
        "        r'\\b(not|never|no way) (really|totally|at all)\\b',  # Contrasting sentiments\n",
        "    ]\n",
        "\n",
        "    # Check sarcasm patterns\n",
        "    for pattern in sarcasm_patterns + punctuation_patterns:\n",
        "        if re.search(pattern, text):\n",
        "            return \"Sarcastic\"\n",
        "\n",
        "    return \"Not Sarcastic\"\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Text Analysis: Sentiment and Sarcasm Detection\")\n",
        "st.write(\"Enter your text below, and the app will predict its sentiment class and sarcasm.\")\n",
        "\n",
        "# Input Text\n",
        "user_input = st.text_area(\"Input Text\", value=\"\", placeholder=\"Type your text here...\")\n",
        "\n",
        "if st.button(\"Analyze\"):\n",
        "    if user_input.strip():\n",
        "        # Predict Sentiment Class\n",
        "        sentiment_result = predict_classes(user_input)\n",
        "\n",
        "        # Predict Sarcasm\n",
        "        sarcasm_result = predict_sarcasm(user_input)\n",
        "\n",
        "        # Display Results\n",
        "        st.write(f\"**Sentiment Class:** {sentiment_result}\")\n",
        "        st.write(f\"**Sarcasm Detection:** {sarcasm_result}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter some text to analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdWxpXVetSsh",
        "outputId": "c4b018df-d19d-4707-abd1-17ab1869789a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "JpBi-6DWyUJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S83bSQyDk1UR"
      },
      "outputs": [],
      "source": [
        "!tensorflowjs_converter --input_format keras /content/model.h5 /content/web_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BS0ZjWBk1UR"
      },
      "outputs": [],
      "source": [
        "!ls /content/web_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E8ixOLxk1UR"
      },
      "outputs": [],
      "source": [
        "# Navigate to the directory\n",
        "%cd /content/index.html\n",
        "\n",
        "# Start the HTTP server\n",
        "!python3 -m http.server\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}